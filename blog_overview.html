<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.5.5, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.5.5, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/1-1.png" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Blog</title>
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Lexend:100,200,300,400,500,600,700,800,900&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lexend:100,200,300,400,500,600,700,800,900&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">
  
  
  
  
</head>
<body>
  
<section data-bs-version="5.1" class="menu menu2 cid-sFF0ciwnEL" once="menu" id="menu2-10">
    
    <nav class="navbar navbar-dropdown navbar-fixed-top navbar-expand-lg">
        <div class="container">
            <div class="navbar-brand">
                
                <span class="navbar-caption-wrap"><a class="navbar-caption text-primary display-7" href="index.html#top">Guoxin Yu @ ICT, CAS.</a></span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbarSupportedContent" data-bs-target="#navbarSupportedContent" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <div class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#top">About me</a></li>
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#content14-q">Research</a></li><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#content14-8">Publication</a></li><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#content5-z">Honours and Awards<br></a></li><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="blog_overview.html">Blog</a></li></ul>
                
                
            </div>
        </div>
    </nav>
</section>


<section data-bs-version="5.1" class="header3 cid-tnwRnHnESK" id="header3-1a">



    <div class="mbr-overlay" style="opacity: 0.2; background-color: rgb(190, 211, 249);"></div>

    <div class="align-center container-fluid">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-8">
                <h1 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>Today is a gift!</strong></h1>
                
                <p class="mbr-text mbr-fonts-style display-7">Share my academic life~</p>
                
            </div>
        </div>
    </div>
</section>



<section data-bs-version="5.1" class="features8 cid-tnwZVJJyRQ" xmlns="http://www.w3.org/1999/html" id="features9-1d">
    <div class="container">

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1111.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "Human-like systematic generalization through a meta-learning neural network" -- Nature2023 main</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        
                                        This paper provdides evidence that neural networks can achieve human-like systematicity when optimized for their compositional skills and introduces the meta-learning for compositionality (MLC) approach for guiding training through a dynamic stream of compositional tasks. 
                                        Comparison results to human experiments demonstrated that only MLC achieves both the systematicity and fexibility needed for human-like generalization.
                                        MLC also advances the compositional skills of machine learning systems in several systematic generalization benchmarks.

                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.11.11</p>
                                    <div class="mbr-section-btn"><a href="file:///Users/yuguoxin/Downloads/s41586-023-06668-3.pdf" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1110.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "MoT: Memory-of-Thought Enables ChatGPT to Self-Improve" -- EMNLP2023 main</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        
                                        (1) Motivation: Existing studies collecting high-quality annotated datasets and fine-tuning the LLM is costly and may decrease its general ability. Humans can improve their own reasoning abilities through the metacognition process and the memory mechanisms, preserve their general abilities. 
                                        (2) Methods: We propose Memory of Thought(MoT) to let LLM think on the unlabeled dataset and save the thoughts in the pre-thinking stage and recall relevant memory in the test stage.
                                        (3) Experiments: Extensive experiments show that MoT can help ChatGPT improve its abilities in arithmetic reasoning, commonsense reasoning, factual reasoning and natural language inference without parameter updates and annotated datasets. 

                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.11.10</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2305.05181" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1102.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "Large Language Models Struggle to Learn Long-Tail Knowledge" -- ICML2022</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        
                                        (1) Motivation: This paper investigates the relationships between the knowledge memorized in LLMs and the information in pre-training datasets scraped from the web.  
                                        (2) Observations: this paper identified these relevant documents by entity linking pre-training datasets and counting documents that contain the same entities as a given question-answer pair and showed that a language model's ability to answer a fact-based question relates to how many documents associated with that question were seen during pre-training. 
                                        They also demonstrated that retrieval-augmented methods could reduce the dependency of LLMs on relevant pre-training information, presenting a promising approach for capturing the long-tail.
                                        (3) Experiments: LLMs are GPT-Neo, BLOOM, and GPT-3. Pre-training datasets are The Pile, ROOTS, C4, PenWebText, and Wikipedia. Test QA datasets are TriviaQA and Natural Questions.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.11.02</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2211.08411" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1025.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!" -- EMNLP2023</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        (1) Motivation: this paper investigates the effectiveness of small pre-trained language models (SLMs) and large language models (LLMs) on few-shot information extraction and found that LLM could resolve hard examples better. 
                                        (2) Methods: this paper have several conclusions. First, LLMs outperform SLMs only when the overall number of annotations is limited. Second, when we increase the number of samples (e.g., a few hundreds), SLMs outperform LLMs by a large margin. Third, calling LLMs API suffers from much higher inference latency and financial cost than finetuning SLMs locally. Last, LLMs are good at hard samples, though bad at easy samples. 
                                        This paper proposed a novel adaptive filter-then-rerank framework to combine SLMs and LLMs considering both performance and cost in practice. The basic idea is that SLMs serve as a filter and LLMs as a reranker. In specific, SLMs make the first round of prediction, and if the sample is a hard one, this paper further passed the top-N candidate labels with highest prediction scores by SLMs to LLMs for reranking.
                                        (3) Experiments: With only 0.5%-13.2% of the samples being reranked, the adaptive filter-then-rerank system surpasses the previous state-of-the-art methods by an average 2.1% F1-score gain.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.10.25</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2303.08559" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1018.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation" -- SIGIR2023</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        (1) Motivation: Retrieval-augmented generation models offer many benefits over standalone language models: besides a textual answer to a given query they provide provenance items retrieved from an updateable knowledge base. However, they are also more complex systems and need to handle long inputs. 
                                        (2) Methods: we introduce FiD-Light to strongly increase the efficiency of the state-of-the-art retrieval-augmented FiD model, while maintaining the same level of effectiveness. FiD-Light model constrains the information flow from the encoder (which encodes passages separately) to the decoder (using concatenated encoded representations). Furthermore, we adapt FiD-Light with re-ranking capabilities through textual source pointers, to improve the top-ranked provenance precision. 
                                        (3) Experiments: Our experiments on a diverse set of seven knowledge intensive tasks (KILT) show FiD-Light consistently improves the Pareto frontier between query latency and effectiveness.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.10.18</p>
                                    <div class="mbr-section-btn"><a href="https://arxiv.org/pdf/2210.08726.pdf" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1017.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "RARR: Researching and Revising What Language Models Say, Using Language Models" -- ACL2023</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        (1) Motivation: A user cannot easily determine whether their outputs are trustworthy or not, because most LMs do not have any built-in mechanism for attribution to external evidence. 
                                        (2) Methods: To enable attribution while still preserving all the powerful advantages of recent generation models, we propose RARR (Retrofit Attribution using Research and Revision), a system that 1) automatically finds attribution for the output of any text generation model, and 2) post-edits the output to fix unsupported content while preserving the original output as much as possible. 
                                        (3) Experiments: RARR significantly improves attribution while otherwise preserving the original input to a much greater degree than previously explored edit models. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.10.17</p>
                                    <div class="mbr-section-btn"><a href="https://arxiv.org/pdf/2210.08726.pdf" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>


        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1016.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "Large Language Models Are Human-Level Prompt Engineers" -- ICLR2023</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        (1) Motivation: Performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans.
                                        (2) Methods: We propose Automatic Prompt Engineer(APE) for automatic instruction generation and selection.
                                        We treat the instruction as the “program,” optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. 
                                        To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction.
                                        (3) Experiments: APE-engineered prompts are able to improve few-shot learning performance, find better zero-shot chain-of- thought prompts, as well as steer models toward truthfulness and/or informativeness.

                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.10.16</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2211.01910" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/m1016.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Combine images online.</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        Combine images online.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.10.16</p>
                                    <div class="mbr-section-btn"><a href="https://fulicat.com/lab/pintu/" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1011.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Ppaer reading "Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration" - EMNLP2023 Findings</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper investigates the LLMs-based conversational agent's proactivity, specifically focusing on three perspectives: clarification, target-guided, and non-collaborative dialogues. 
                                        They proposed the proactive chain of thought prompting scheme, which analyzes the next action to take by performing dynamic reasoning and planning for reaching the conversational goal. 
                                        The experiments are conducted from the above-mentioned three perspectives and they compared the performance of standard prompting, proactive prompting, and the proposed proactive chain-of-thought prompting schemes. 
                                        This paper inspired me to think about an idea that gives LLMs alternative actions. 
                                        In each step, the LLM could select an action and respond accordingly. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.10.11</p>
                                    <div class="mbr-section-btn"><a href="https://arxiv.org/abs/2305.13626" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model1010.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Lecture Notes: "Towards Generative Search and Recommendation".</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                    Introduce the use of LLMs for information seeking and the research directions in LLMs.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.10.10</p>
                                    <div class="mbr-section-btn"><a href="./LectureNotes.html" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0921.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough reading "Contrastive Decoding Improves Reasoning in Large Language Models - arxiv2023".</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                    This paper demonstrates that the existing contrastive decoding method could achieve large out-of-the-box improvements over greedy decoding on many reasoning tasks. 
                                    Contrastive Decoding (CD) searches for strings that maximize a weighted difference in likelihood between a stronger expert and a weaker amateur model, and was shown by Li et al. to outperform existing methods for open-ended text generation. 
                                    It achieves this by avoiding undesirable modes of the expert model’s distributions. 
                                    They show that Contrastive Decoding outperforms greedy decoding on reasoning problems. 
                                    Contrastive Decoding leads LLaMA-65B to outperform LLaMA 2, GPT-3.5 and PaLM 2-L on the HellaSwag commonsense reasoning benchmark, and to outperform LLaMA 2, GPT-3.5 and PaLM-540B on the GSM8K math word reasoning benchmark.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.20</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2309.09117" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0920.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit - arxiv2023".</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                    This paper proposed a RETA-LLM, which contains three modules: (1) a request rewriting module ; (2) a passage extraction module ; (3) a fact checking module. 
                                    RETA-LLM is part of YuLan, a open source LLM initiative proposed by Gaoling School of Ar- tificial Intelligence, Renmin University of China.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.20</p>
                                    <div class="mbr-section-btn"><a href="arXiv:2306.05212v1" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0919.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper reading "Augmented Large Language Models with Parametric Knowledge Guiding - arxiv2023".</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                    Following the paper "GENERATE RATHER THAN RETRIEVE: LARGE LANGUAGE MODELS ARE STRONG CONTEXT GENERATORS - ICLR2023", 
                                    this paper proposed a novel Parametric Knowledge Guiding framework (generate-then-read).
                                    This method used Llama-7B as a white box language model, which first generates relevant knowledge according to prompts. 
                                    Then the generated knowledge is adapted to fine-tune the Llama-7B (Instruct tuning). 
                                    Finally, the fine-tuned Llama-7B (white box) is equipped with GPT-3.5 (black box) to solve different downstream tasks. 
                                    I think this method is effective, but it feels a bit like "killing a chicken without using a cow knife".
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.18</p>
                                    <div class="mbr-section-btn"><a href="https://arxiv.org/abs/2305.04757" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0918-1.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Seaborn: statistical data visualization</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        Mark a good drawing tool. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.17</p>
                                    <div class="mbr-section-btn"><a href="https://seaborn.pydata.org/examples/kde_ridgeplot.html" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0918.webp" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>A paper list about Large Language Models</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        Record a paper list for LLMs. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.17</p>
                                    <div class="mbr-section-btn"><a href="https://github.com/Mooler0410/LLMsPracticalGuide#bert-style-language-models-encoder-decoder-or-encoder-only" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0915.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "Query Rewriting for Retrieval-Augmented Large Language Models"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper proposed a rewrite-retrieve-read pipeline to improve the performance of LLM. 
                                        Different from existing methods of adapting the retriever or simulating the reader, this paper proposed to rewrite the query with a small language model. 
                                        Specifically, they first prompt the LLM to generate some pseudo data to train the warm-up rewriter. Then the PPO is used to optimize the rewriter. 
                                        The experiments seem to be incomplete, but this paper provides a novel idea and perspective for retrieval-augmented LLMs. 
                                        The PPO should be further figured out. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.15</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2305.14283" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0914.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        Existing retrieval-augmented LLMs adopt one-time retrieval, which (1) fails to process all the knowledge as a whole during the generation process; (2) invokes retrieval multiple times and may frequently change the prompts by updating newly retrieved knowledge. 
                                        This paper proposed an iterative retrieval-generation synergy, which alternates between a retrieval-augmented generation process and a generation-augmented retrieval process. 
                                        A knowledge distillation from a re-ranker is used to help the retriever better address the semantic gaps between a question and its supporting knowledge.
                                        Experiments are conducted on four QA datasets. An ACC* metric also be adopted to evaluate the model in a more robust way. 
                                        This paradigm is similar to the idea in our paper "<a href="https://www.google.com/url?client=internal-element-cse&cx=000299513257099441687:fkkgoogvtaw&q=https://aclanthology.org/2021.findings-emnlp.115&sa=U&ved=2ahUKEwjto-76ltf-AhVql1YBHWMIB88QFnoECAkQAQ&usg=AOvVaw08pLIh9StQCjd_YHKPGgGJ">self Question-answering ...</a>".
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.14</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2305.15294" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0912-1.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "In-Context Demonstration Selection with Cross Entropy Difference"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper proposed to select in-context demonstrations based on cross-entropy difference, which is based on the idea of meta-gradient. 
                                        This paper also provides theoretical guidance for why selecting demonstrations based on their gradient alignment with test examples is an effective heuristic.
                                        This paper seems to be an unfinished paper, but it provides a good idea and a new perspective on demonstration selection.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.12</p>
                                    <div class="mbr-section-btn"><a href="http://arxiv.org/abs/2305.14726" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0912.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models - Arxiv2023"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                    This paper proposed a development and evaluation framework for retrieval-augmented LLMs (R-LLMs), namely RALLE. 
                                    Current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation. 
                                    With RALLE, developers can easily develop and evaluate R-LLMs, improving hand-crafted prompts, assessing individual inference processes, and objectively measuring overall system performance quantitatively. 
                                    This paper provides a graphical interface for users to select, combine, and test various retrievers and LLMs. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.12</p>
                                    <div class="mbr-section-btn"><a href="https://arxiv.org/abs/2308.10633" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0908.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "GENERATE RATHER THAN RETRIEVE: LARGE LANGUAGE MODELS ARE STRONG CONTEXT GENERATORS - ICLR2023"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                    Previous retrieval-augmented methods employ a retrieve-then-read pipeline, which suffers from three drawbacks:
                                    (1) candidate documents for retrieval are chunked and fixed, containing noisy information;
                                    (2) interactions between the input and documents are shallow; 
                                    (3) encoding a large number of candidates is time-consuming. <br>
                                    This paper proposed a generate-then-read method, which first prompts LLMs to generate contextual documents and then uses them to obtain the answer. 
                                    A clustering-based prompting approach to generate multiple diverse contextual documents is proposed to increase the likelihood of covering the answers. 
                                    Experiments on three knowledge-intensive NLP tasks prove the superiority of the proposed method compared to previous augmented methods. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.08</p>
                                    <div class="mbr-section-btn"><a href="https://arxiv.org/abs/2209.10063" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0907.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper investigates the knowledge boundary of LMMs and how retrieval augmentation affects LLMs on open-domain tasks. 
                                        This study answere three questions:
                                        1. To what extent can LLMs perceive their factual knowledge boundaries? 
                                        LLMs perceive their factual knowledge bound- ary inaccurately and have a tendency to be over- confident. In
                                        2. What effect does re- trieval augmentation have on LLMs? 
                                        (1) LLMs cannot sufficiently utilize the knowledge they possess, while retrieval augmentation can serve as a valuable knowledge supplement for LLMs.
                                        (2) Retrieval augmentation improves LLM’s ability to perceive their factual knowledge boundaries. 
                                        (3) More supporting documents continuously improve the performance of retrieval-augmented LLMs. 
                                        (4) Retrieval augmentation can change the preference of LLMs towards different query categories.
                                        3. How do supporting documents with different characteristics
                                        (1) LLMs demonstrate enhanced capabilities in QA abilities and perception of knowledge boundaries when provided with higher quality supporting documents.
                                        (2) LLMs tend to rely on the given supporting documents to answer. 
                                        (3) The level of confidence and reliance on supporting documents of LLMs is determined by the relevance between the question and the supporting documents. <br>
                                        The experiments are conducted by the usage of LLMs APIs. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.07</p>
                                    <div class="mbr-section-btn"><a href="https://github. com/RUCAIBox/LLM-Knowledge-Boundary" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0906-2.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "Z-ICL : Zero-Shot In-Context Learning with Pseudo-Demonstrations"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper introduce Z-ICL: Zero-shot In-Context Learning through creating pseudo-demonstrations, which achieves results on par with in-context learning from gold demonstrations.
                                        This paper first explain the Copying Effect Hypothesis in ICL, which means that ICL tends to copy the input-label distribution of similar demonstration. 
                                        To alleviate the copy effect, this paper proposed to retrieve physical neighbors from a raw corpus. 
                                        Then synonym labels are randomly assigned to the neighbors. 
                                        Finally, they concatenate the pseudo-demonstrations with the initial input x and inference the results. 
                                        The authors think future work can explore better construct- ing the pseudo-demonstrations.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.06</p>
                                    <div class="mbr-section-btn"><a href="https://aclanthology.org/2023.acl-long.129/" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0906-1.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper investigates that large language models store popular factual knowledge in parametric memorization while struggles with less popular knowledge (long tail).
                                        The proposed adaptive retriever uses retrieval when the popularity of input is lower than a threshold.
                                        The analysis results are as follows: 
                                        1. Memorization Depends on Popularity and Relationship Type.
                                        (1) Subject entity popularity predicts memorization: more popular subject entity indicates better the memorization. 
                                        (2) Relationship types affects memorization: some relationships are easier to be memorized. 
                                        (3) Scaling may not help with tail knowledge. 
                                        (4) Relationship type results breakdown. 
                                        2. Non-parametric Memory Complements Parametric Memory. 
                                        (1) Retrieval largely improves performance.
                                        (2) Non-parametric memorizations are effective for less popular facts.
                                        (3) Parametric memorizations may mislead LMs. 
                                        3. Adaptive Retrieval: Using Retrieval Only Where It Helps. 
                                        Adaptive Retrieval improves performance and reduces the inference time cost. The threshold shift with LM scale. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.06</p>
                                    <div class="mbr-section-btn"><a href="https://aclanthology.org/2023.acl-long.546/" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0906.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper Reading "Making pre-trained language models better few-shot learners"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        Since the ICL (GPT-3) is not parametric efficient, this paper aims to study few-shot learning in a more practical scenario, where they use smaller language models for which fine-tuning is computationally efficient. 
                                        On the one hand, they proposed an automating prompt generation method, which could automatically map a class with a word and generate a template to organize an examples pair.
                                        On the other hand, they designed a dynamic demonstrations selection method to selecte demonstrations for each class and improve the performance of downstream tasks. 
                                        Experiments prove the effectiveness of different generated templates and compare them with manully templates. 
                                        Please refer to the specific paper for more experimental details. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.06</p>
                                    <div class="mbr-section-btn"><a href="https://aclanthology.org/2021.acl-long.295/" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0905.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Rough Reading "Understanding In-Context Learning via Supportive Pretraining Data"</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper investigates how the pretraining data helps in-context learning. 
                                        The authors adopt an iterative, gradient-based method to find a small subset of the pretraining data that supports ICL. 
                                        They find that continued pretraining on the selected subset improves the ICL performance compared to a random subset. 
                                        They have 3 interesting observations: (1) the supportive pretraining data do not have an inevitable domain relevance with the downstream task; 
                                        (2) The supportive pretraining data have a higher mass of rarely occurring, long-tail tokens; 
                                        (3) The supportive pretraining data are challenging examples where the information gained from long-range context is below average. 
                                        The metrics used in this paper to evaluate the relationships between pretraining data and the input text are very reasonable and impressive.
                                        <strong>This paper uses the similarity between gradients to find supportive pretraining data, which provides a guidance for the direction the model parameters should be updated towards to be better at ICL. </strong>
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.05</p>
                                    <div class="mbr-section-btn"><a href="https://aclanthology.org/2023.acl-long.708/" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>


        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/DPP_example.webp" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>行列式点过程（Determinantal Point Process, DPP）</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        In mathematics, a determinantal point process is a stochastic point process, the probability distribution of which is characterized as a determinant of some function. -- Wikipedia.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.04</p>
                                    <div class="mbr-section-btn"><a href="DPP.html" class="btn btn-white display-4" target="_blank">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>


        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0904.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper Reading "Diverse Demonstrations Improve In-context Compositional Generalization" -- ACL2023 </strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper proposed a new demonstration selection method for in-context learning in the setup of compositional generalization. Considering that there is no example that is similar enough to the input, the proposed method takes into account both the similarity and diversity among different demonstrations. Specifically, they proposed two approaches for increasing diversity: (a) a cover-based approach; and (b) an approach that selects a subset of examples that are most dissimilar with each other (using DPP).  Experiments across three compositional generalization semantic parsing datasets show that combining diverse demonstrations with in-context learning substantially improves performance in the pure in-context learning setup and when combined with fine-tuning.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.04</p>
                                    <div class="mbr-section-btn"><a href="https://aclanthology.org/2023.acl-long.78/" class="btn btn-white display-4" target="_blank">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    
    
        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0902.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper Reading "Unified Demonstration Retriever for In-Context Learning" -- ACL2023 Oral </strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper proposed to retrieve demonstrations from the training set for ICL, which could jointly train several NLP tasks and yeild a unified model.
                                        This paper convert the demonstration selection as a list-wise ranking problem and design an interative candidates selection method. 
                                        Experiments on 30+ NLP tasks proved the effectiveness of the proposed framework. The experimental amount is impressive.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.02</p>
                                    <div class="mbr-section-btn"><a href="https://aclanthology.org/2023.acl-long.256/" class="btn btn-white display-4" target="_blank">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    
        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0901.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper Reading "Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering" -- ACL2023 Oral </strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper proposed a new task, namely self-adaptive in-context learning, which seeks to construct good-performing in-context example organization for each testing sample individually.
                                        Existing methods could be sub-optimal because they are in corpus-level. This paper proposed an instance-level method containing selection and ranking to find better examples organizations for ICL. 
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.01</p>
                                    <div class="mbr-section-btn"><a href="https://openreview.net/pdf?id=buoL9Vd9VY" class="btn btn-white display-4" target="_blank">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    
        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/model0822.png" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Paper Reading "Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In" -- ACL2023 Oral </strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        This paper proposed a simple yet effective method, namely augmentation-adapted retriever (AAR), 
                                        which pre-trained a retriever based on a source LM and plugged the retriever into a target unseen LM. 
                                        The experiments and analysis are insightful.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.08.22</p>
                                    <div class="mbr-section-btn"><a href="https://aclanthology.org/2023.acl-long.136/" class="btn btn-white display-4" target="_blank">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/tangbao.jpeg" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Sweet baby and Tiny.</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        Sweet Baby is a black schnauzer, born in October 2019.
                                        Tiny is a brown Teddy dog, born in April 2020.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2023.09.19</p>
                                    <div class="mbr-section-btn"><a href="page3.html" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/wechatimg64-2.jpeg" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>My first blog.</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">
                                        Welcome to my first blog.  I share my daily life and record my research process.
                                    </p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2022.11.18</p>
                                    <div class="mbr-section-btn"><a href="paper_reading0822.html" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-wrapper">
                <div class="row align-items-center">
                    <div class="col-12 col-md-3">
                        <div class="image-wrapper">
                            <img src="assets/images/wechatimg62-2.jpeg" alt="Mobirise">
                        </div>
                    </div>
                    <div class="col-12 col-md">
                        <div class="card-box">
                            <div class="row">
                                <div class="col-md">
                                    <h6 class="card-title mbr-fonts-style display-9"><strong>Coming soon.</strong></h6>
                                    <p class="mbr-text mbr-fonts-style display-10">There is nothing</p>
                                </div>
                                <div class="col-md-auto">
                                    <p class="price mbr-fonts-style display-7">2022.--.--</p>
                                    <div class="mbr-section-btn"><a href="page3.html" class="btn btn-white display-4">Learn more</a></div>
                                </div>
                                <div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
    </div>
</section>

<section data-bs-version="5.1" class="footer7 cid-tnx0ReMrpm" once="footers" id="footer7-1f">

    

    

    <div class="container">
        <div class="media-container-row align-center mbr-white">
            <div class="col-12">
                <p class="mbr-text mb-0 mbr-fonts-style display-7">Only has compared to the others early, diligently, can feel the successful taste.</p>
            </div>
        </div>
    </div>
</section><section style="background-color: #fff; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif; color:#aaa; font-size:12px; padding: 0; align-items: center; display: flex;"><a href="https://mobirise.site/l" style="flex: 1 1; height: 3rem; padding-left: 1rem;"></a><p style="flex: 0 0 auto; margin:0; padding-right:1rem;">Site was <a href="https://mobirise.site/g" style="color:#aaa;">designed</a> with Mobirise</p></section><script src="assets/bootstrap/js/bootstrap.bundle.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/ytplayer/index.js"></script>  <script src="assets/dropdown/js/navbar-dropdown.js"></script>  <script src="assets/theme/js/script.js"></script>  
  
  
</body>
</html>